# Generative AI Learnings

A comprehensive repository documenting my journey into Generative AI, Machine Learning, and Deep Learning. This repo serves as a knowledge base where I share concepts, implementations, and insights as I explore the fascinating world of AI.

## About This Repository

As a software engineer passionate about emerging technologies, I'm documenting my learning path through:
- Core ML/DL concepts
- Generative AI techniques
- Practical implementations
- Research papers and insights
- Hands-on projects

## Repository Structure

```
├── 01-fundamentals/          # AI, ML, DL basics
├── 02-neural-networks/       # ANNs, CNNs, RNNs, Transformers
│   └── training-concepts/    # Training, Overfitting, Normalization
├── 03-generative-models/     # GANs, VAEs, Diffusion Models
├── 04-large-language-models/ # LLMs, Fine-tuning, Prompt Engineering
├── 05-implementations/       # Code examples and projects
├── 06-research-notes/        # Paper summaries and insights
└── resources/                # Helpful links, books, courses
```

## Topics Covered

### Fundamentals
- [x] Artificial Neural Networks (ANNs)
- [ ] Activation Functions
- [ ] Loss Functions
- [ ] Optimization Algorithms

### Neural Network Training
- [x] Overfitting and Underfitting
- [x] Normalization Techniques (Min-Max, Z-Score)
- [ ] Regularization Methods
- [ ] Batch Normalization
- [ ] Learning Rate Scheduling

### Neural Network Architectures
- [ ] Convolutional Neural Networks (CNNs)
- [ ] Recurrent Neural Networks (RNNs)
- [ ] Long Short-Term Memory (LSTM)
- [ ] Transformers

### Generative AI
- [ ] Generative Adversarial Networks (GANs)
- [ ] Variational Autoencoders (VAEs)
- [ ] Diffusion Models
- [ ] Large Language Models (LLMs)

### Advanced Topics
- [ ] Fine-tuning Techniques
- [ ] Prompt Engineering
- [ ] Retrieval-Augmented Generation (RAG)
- [ ] Model Deployment

## Recent Updates

### February 20, 2026
- Added comprehensive guide on [Neural Network Training Concepts](./02-neural-networks/training-concepts/nn-training-guide.md)
  - Overfitting vs. Underfitting with real-world examples
  - Normalization techniques (Min-Max and Z-Score)
  - Why normalization matters for model performance

## Learning Goals

1. Build strong foundations in AI/ML/DL concepts
2. Understand generative model architectures
3. Implement models from scratch
4. Work with modern frameworks (PyTorch, TensorFlow, Hugging Face)
5. Deploy AI applications

## Tech Stack

- **Languages**: Python
- **Frameworks**: PyTorch, TensorFlow, Keras
- **Tools**: Jupyter Notebooks, Google Colab
- **Libraries**: NumPy, Pandas, Scikit-learn, Hugging Face Transformers

## How to Use This Repository

Each topic folder contains:
- **README.md**: Overview and key concepts
- **notes.md**: Detailed explanations and observations
- **code/**: Implementation examples
- **resources.md**: References and further reading

## Contributing

This is a personal learning repository, but suggestions and discussions are welcome! Feel free to:
- Open issues for corrections or suggestions
- Share additional resources
- Discuss concepts in the Discussions tab

## Connect

- **GitHub**: [@Bharanidharan2K](https://github.com/Bharanidharan2K)
- **Location**: Tamil Nadu, India

## License

MIT License - Feel free to use this content for your own learning!

---

*Last Updated: February 20, 2026*
*Status: Actively Learning*
